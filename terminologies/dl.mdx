---
slug: neuron
title: 神经元
authors: [heliannuuthus]
description: 神经元是深度学习中的基本单元，通常由输入、权重矩阵、偏置向量和激活函数组成。本质是执行线性计算，并将其映射到非线性空间。
---

> 神经元是深度学习中的基本单元，通常由输入、权重矩阵、偏置向量和激活函数组成。本质是执行线性计算，并将其映射到非线性空间。

输入向量通过权重矩阵进行加权计算，然后加上向量偏置，完成线性计算，最后通过激活函数将计算结果映射到非线性空间。

常规的 3 层神经网络结构如下：

1. 输入向量 $x$ 通过第一层权重矩阵 $W_1$ 进行加权计算，然后加上第一层偏置向量 $b_1$，得到第一层输出向量 $h_1$。
2. 第一层输出向量 $h_1$ 通过第二层权重矩阵 $W_2$ 进行加权计算，然后加上第二层偏置向量 $b_2$，得到第二层输出向量 $h_2$。
3. 第二层输出向量 $h_2$ 通过激活函数 $f$ 进行非线性计算，得到最终输出向量 $y$。

$$
y = f(W_2 h_2 + b_2)
$$

其中，$W_1$ 是第一层权重矩阵，$b_1$ 是第一层偏置向量，$W_2$ 是第二层权重矩阵，$b_2$ 是第二层偏置向量，$f$ 是激活函数。

---
slug: activation-function
title: 激活函数
authors: [heliannuuthus]
description: 激活函数是神经元中的非线性函数，用于将线性计算结果映射到非线性空间。
---

> 激活函数是神经元中的非线性函数，用于将线性计算结果映射到非线性空间。

常见的激活函数有：

- [ReLU](<https://en.wikipedia.org/wiki/Rectifier_(neural_networks)>)
- [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function)
- [Tanh](https://en.wikipedia.org/wiki/Hyperbolic_tangent)
- [Softmax](https://en.wikipedia.org/wiki/Softmax_function)

---
slug: supervised-learning
title: 监督学习
authors: [heliannuuthus]
description: 机器学习的一个核心分支，旨在从**已标注**的训练数据集中学习一个映射关系（模型），以预测新的未知数据的标签。
---

- 输入：也称为`特征`或`自变量`
- 输出：也称为`标签`或`因变量`
- 训练数据集：包含已标注的输入和输出数据，以 $({输入}, {输出})$ 的形式表示
- 模型：一个数学函数，训练模型的目标就是找到一个函数 $f$ 使得 $f(x) \approx y$
- 学习过程：在训练数据集上，通过优化模型参数，使得模型能够更好地拟合训练数据集

:::nerd
常见的监督学习任务包括：
- 分类：将输入数据分为不同的类别，例如垃圾邮件检测、手写数字识别等
- 回归：预测连续值，例如房价预测、股票价格预测等
- 文本生成：通过大量的文本、词元和语法进行训练，达到预测下一个词元的目的
- 图像生成：通过对文字的理解，泛化生成能力转换为图像生成
:::

---
slug: supervised-fine-tuning
title: 监督微调
authors: [heliannuuthus]
description: 监督微调是一种通过:term[监督学习]{./terms/dl#supervised-learning}的方式，使用标注数据对预训练过的模型进行训练的方法。
---

|特性|监督学习|监督微调|
|---|---|---|
|定义|广泛的**机器学习范式**，从已标注的数据中学习输入到输出的映射关系|一个**具体的训练阶段**，在预训练模型上用特定的任务标注数据进一步训练|
|模型|随机初始化的模型|预训练的模型|
|数据|任何标注的数据，数据的数量和质量决定了模型的上限|使用**小规模、高质量、任务特定的标注数据**|
|目标|学习一个通用的映射函数，解决一个特定的任务|使模型与特定任务对齐，更符合特定的需求|
|成本|需要大量的标注数据、强大的算力|相对较低，需要小规模、高质量、任务特定的标注数据|

---
slug: reinforcement-learning
title: 强化学习
authors: [heliannuuthus]
description: 强化学习与监督学习不同，强化学习通过与环境交互，学习一个策略，使得长期回报最大化。
---

- 策略：智能体的行为函数。根据当前的状态决定要执行什么动作
- 价值函数：预测并评估一个状态或动作的:ctip[长期价值]{id="未来可能获得的所有奖励的总和"}
- :ctip[环境模型]{id="并不是所有 RL 都需要环境模型"}：一个数学函数，标识智能体对环境运行方式的理解，用于预测下一步会变成什么状态、获得什么奖励

:::nerd
- 通过与环境交互的经验序列来学习一系列的动作以最大化累计奖励
- 智能体获取到的反馈信息是**延迟**的，并且是**稀疏**的
:::